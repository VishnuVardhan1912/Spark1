{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268a0333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe08b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087546f7",
   "metadata": {},
   "source": [
    "## RDD actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1d1542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To call RDD we use parallelize() method\n",
    "\n",
    "data = [1,2,3,4,5]\n",
    "rDD = sc.parallelize(data, 4)\n",
    "rDD.collect()   # Running a action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa27db39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[2, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "A = sc.parallelize([2,4,7])\n",
    "L = A.collect()\n",
    "print(type(L))\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f45947a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(lambda x,y: x*y) # RDD action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4355ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([5,3,1,2])\n",
    "rdd.takeOrdered(3) # order's the data and returns 3 values. It is a RDD action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e843d926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count() # RDD action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a397227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(2) # RDD action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ca87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd.saveAsTextFile(\"text1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1911d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['this', 'is', 'the', 'best', 'mac', 'ever']\n",
    "wordRDD = sc.parallelize(words)\n",
    "wordRDD.reduce(lambda w,v: w if len(w) < len(v) else v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "755870b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = sc.parallelize([1,3,5,2])\n",
    "B.reduce(lambda x,y: x - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05816ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'that'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words1 = ['this', 'that', 'rectangle', 'round', 'sharp']\n",
    "wordRDD1 = sc.parallelize(words1)\n",
    "\n",
    "def lesserThan(x, y):\n",
    "    if len(x) < len(y): return x\n",
    "    elif len(y) < len(x): return y\n",
    "    else:   # lengths are equal,  compare lexicographically\n",
    "        if x<y:\n",
    "            return x\n",
    "        else:\n",
    "            return y\n",
    "wordRDD1.reduce(lesserThan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512cbf9e",
   "metadata": {},
   "source": [
    "## Spark Paritions, Coalesce and Repartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c22ce864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "A = sc.parallelize(range(100000))\n",
    "print(A.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b67f3a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "D = A.repartition(6)\n",
    "print(D.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d23a622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "D = A.coalesce(4)\n",
    "print(D.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df094b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "A = sc.parallelize(range(1000000), numSlices=12)\n",
    "print(A.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b58a784b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf3c08",
   "metadata": {},
   "source": [
    "## RDD Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "308dca60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multipicaltion of number with scalar\n",
    "\n",
    "rdd = sc.parallelize([1,2,3,4])\n",
    "rdd.map(lambda x:x*2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fb110c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter number according to condition\n",
    "\n",
    "rdd.filter(lambda x:x%2 == 0).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1780532d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To find distinct numbers\n",
    "\n",
    "rdd2 = sc.parallelize([1,4,2,2,3])\n",
    "rdd2.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e5bd8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "B = sc.parallelize([1,2,3,4]* int(n/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8655b846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of elements in B that are > 3 = 250000\n",
      "the number of elements in B that are > 3 = 250000\n"
     ]
    }
   ],
   "source": [
    "def greaterthan(x):\n",
    "    return x > 3\n",
    "print('the number of elements in B that are > 3 =',B.filter(greaterthan).count())\n",
    "\n",
    "print('the number of elements in B that are > 3 =',B.filter(lambda n:n > 3).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "001a3371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuplicateRDD= [1, 1, 2, 2, 3, 3]\n",
      "DistinctRDD= [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate element in DupliateRDD, we get distinct RDD\n",
    "\n",
    "DuplicateRDD = sc.parallelize([1,1,2,2,3,3])\n",
    "print('DuplicateRDD=',DuplicateRDD.collect())\n",
    "print('DistinctRDD=',DuplicateRDD.distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "856511a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map: [['you', 'are', 'my', 'sunshine'], ['my', 'only', 'sunshine']]\n",
      "flatmap: ['you', 'are', 'my', 'sunshine', 'my', 'only', 'sunshine']\n"
     ]
    }
   ],
   "source": [
    "text=[\"you are my sunshine\", \"my only sunshine\"]\n",
    "text_file = sc.parallelize(text)\n",
    "\n",
    "# map each line in text to a list of words\n",
    "\n",
    "print('map:', text_file.map(lambda line: line.split(\" \")).collect())\n",
    "\n",
    "# create a single list of words by combining the words from all of the lines\n",
    "\n",
    "print('flatmap:', text_file.flatMap(lambda line: line.split(\" \")).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6699082f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1= [1, 1, 2, 3]\n",
      "rdd2= ['a', 'b', 1]\n",
      "union as bags = [1, 1, 2, 3, 'a', 'b', 1]\n",
      "union as sets = [1, 2, 3, 'b', 'a']\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([1,1,2,3])\n",
    "rdd2 = sc.parallelize(['a', 'b', 1])\n",
    "print('rdd1=', rdd1.collect())\n",
    "print('rdd2=', rdd2.collect())\n",
    "print('union as bags =', rdd1.union(rdd2).collect())\n",
    "print('union as sets =', rdd1.union(rdd2).distinct().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8d1fc",
   "metadata": {},
   "source": [
    "## Spark pair RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1a5a6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (2, 4), (3, 9), (4, 16), (2, 4), (5, 25), (6, 36)]\n"
     ]
    }
   ],
   "source": [
    "regular_rdd = sc.parallelize([1,2,3,4,2,5,6])\n",
    "pair_rdd = regular_rdd.map(lambda x: (x, x*x))\n",
    "print(pair_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fed7382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original RDD : [(1, 2), (2, 4), (2, 6)]\n",
      "After transformation : [(1, 2), (2, 10)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(1,2), (2, 4), (2, 6)])\n",
    "print(\"Original RDD :\", rdd.collect())\n",
    "print(\"After transformation :\", rdd.reduceByKey(lambda a,b: a+b).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b7b87bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original RDD:  [(1, 2), (1, 4), (3, 6)]\n",
      "After transformation : [(1, 2), (1, 4), (3, 6)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(1,2), (1,4), (3,6)])\n",
    "print(\"original RDD: \", rdd.collect())\n",
    "print(\"After transformation :\", rdd.sortByKey().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b9935f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original RDD [(1, 2), (2, 4), (2, 6)]\n",
      "After transformation :  [(1, <pyspark.resultiterable.ResultIterable object at 0x000002417ED97B20>), (2, <pyspark.resultiterable.ResultIterable object at 0x000002417EE74820>)]\n",
      "After transformation :  [(1, [2]), (2, [4, 6])]\n",
      "After transformation :  [(1, [4]), (2, [8, 12])]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(1,2), (2,4), (2,6)])\n",
    "print(\"original RDD\", rdd.collect())\n",
    "print(\"After transformation : \", rdd.groupByKey().collect())\n",
    "print(\"After transformation : \", rdd.groupByKey().mapValues(lambda x:[a for a in x]).collect())\n",
    "print(\"After transformation : \", rdd.groupByKey().mapValues(lambda x:[a+a for a in x]).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28396cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original RDD [(1, 2), (2, 1), (2, 2)]\n",
      "After transformtaion:  [(1, 2), (1, 3), (2, 1), (2, 2), (2, 2), (2, 3)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(1,2), (2,1), (2,2)])\n",
    "print(\"Original RDD\", rdd.collect())\n",
    "\n",
    "# the lambda function generates for each number i, an iterator that produces i, i+1\n",
    "print(\"After transformtaion: \", rdd.flatMapValues(lambda x: list(range(x, x+2))).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d11e70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1= [(1, 2), (2, 1), (2, 2)]\n",
      "rdd2= [(2, 5), (3, 1)]\n",
      "Result: [(1, (2, None)), (2, (1, 5)), (2, (2, 5))]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([(1,2), (2,1), (2,2)])\n",
    "rdd2 = sc.parallelize([(2,5), (3,1)])\n",
    "print(\"rdd1=\", rdd1.collect())\n",
    "print(\"rdd2=\", rdd2.collect())\n",
    "print(\"Result:\", rdd1.leftOuterJoin(rdd2).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "446418e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1= [(1, 2), (2, 1), (2, 2)]\n",
      "rdd2= [(2, 5), (3, 1)]\n",
      "Result: [(2, (1, 5)), (2, (2, 5))]\n"
     ]
    }
   ],
   "source": [
    "print(\"rdd1=\", rdd1.collect())\n",
    "print(\"rdd2=\", rdd2.collect())\n",
    "print(\"Result:\", rdd1.join(rdd2).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb6f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be63a030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
